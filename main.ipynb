{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39c71e0e",
   "metadata": {},
   "source": [
    "# LeRobot v0.4.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878b6d63",
   "metadata": {},
   "source": [
    "## 概要\n",
    "\n",
    "[LeRobot v0.4.0][1]の新機能:\n",
    "\n",
    "[1]: https://github.com/huggingface/lerobot/releases/tag/v0.4.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f960554",
   "metadata": {},
   "source": [
    "- Dataset v3の導入\n",
    "    - 1エピソード1ファイルから、複数のエピソードを単一のParquet/MP4ファイルに集約する形式に変更\n",
    "    - エピソードの参照にリレーショナルメタデータを使用\n",
    "    - StreamingLeRobotDatasetによりデータセットのストリームでのダウンロードが可能になった\n",
    "    - v2.1データセットをv3に変換するスクリプトを追加 \n",
    "- 新しいポリシーの追加\n",
    "    - NVIDIA GR00TN 1.5を追加\n",
    "    - LiberoとMetaWorldのシミュレーション環境を追加\n",
    "    - Reachy 2ロボットとIntel XPUバックエンドへの対応を追加\n",
    "- パフォーマンスの向上\n",
    "    - accelerateライブラリを用いたマルチGPUトレーニングに対応\n",
    "    - データ拡張機能にアフィン変換を追加\n",
    "    - APIの拡張（build_inference_frame・make_robot_action）\n",
    "- コードベースの大幅なリファクタリング\n",
    "    - RL・非同期処理関連の実装がトップレベルに移動\n",
    "    - mypyによる型チェックを導入\n",
    "    - 古いコンポーネントを非推奨化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd6804d",
   "metadata": {},
   "source": [
    "## 検証設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10b493a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104dec33",
   "metadata": {},
   "source": [
    "## インストール"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5b82af",
   "metadata": {},
   "source": [
    "[Install LeRobot][1]\n",
    "\n",
    "[1]: https://huggingface.co/docs/lerobot/en/installation#install-lerobot-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8904fc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "assert torch.cuda.is_available(), \"CUDA is not available\"\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f3cc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install ffmpeg=7.1.1 -c conda-forge -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671a378a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pypi.org/project/torchcodec/\n",
    "%pip install -U \"torchcodec<0.3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0782074",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchcodec\n",
    "torchcodec.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc033614",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python --version # 3.10\n",
    "!ffmpeg -version # 7.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2824f527",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists(\"lerobot\"):\n",
    "    !git clone https://github.com/huggingface/lerobot.git\n",
    "\n",
    "%cd lerobot\n",
    "%pip install -qe . # LeRobotの依存関係をインストール\n",
    "%pip show lerobot # 0.4.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6577d074",
   "metadata": {},
   "source": [
    "## Dataset v3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1789dac1",
   "metadata": {},
   "source": [
    "### エピソードベースからファイルベースへ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daeef370",
   "metadata": {},
   "source": [
    "Dataset v2.1は、ファイルシステムの制限により数百万ものエピソードに対応できなかった\n",
    "\n",
    "Dataset v3では、複数のエピソードをまとめたファイルベースに変更され、より大きなファイルで管理するようになった:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90da19cf",
   "metadata": {},
   "source": [
    "![](image/dataset.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7fbec10",
   "metadata": {},
   "source": [
    "### データセットの構成\n",
    "\n",
    "- テーブルデータ\n",
    "    - 状態・アクション・タイムスタンプ\n",
    "    - Apache Parquet形式\n",
    "- 視覚データ\n",
    "    - カメラフレームは連結されMP4にエンコード\n",
    "    - 同一エピソードでグループ化\n",
    "    - シャーディングはカメラごとに行う\n",
    "- メタデータ\n",
    "    - フレームレート・統計量・共有Parquet/MP4ファイルへのエピソードの開始終了オフセット \n",
    "    - JSON・Parquet形式"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d265109d",
   "metadata": {},
   "source": [
    "### v2.1からv3.0への移行"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133b617f",
   "metadata": {},
   "source": [
    "コンバーターの動作:\n",
    "\n",
    "- Parquetファイルを集約\n",
    "- MP4ファイルを集約\n",
    "- meta/episodes/*をエピソードごとの長さ、タスク、バイト・フレームオフセットで更新する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b837b385",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "HF_TOKEN = os.getenv(\"HF_TOKEN\")\n",
    "assert HF_TOKEN is not None, \"Please set HF_TOKEN in the .env file\"\n",
    "\n",
    "# リポジトリを指定\n",
    "repo_id = \"EngineerCafeJP/record-test-2025-10-07-21-26-29\"\n",
    "\n",
    "# convert_dataset_v21_to_v30.pyを実行してデータセットを変換し、上書きアップロード\n",
    "!export HF_TOKEN=$HF_TOKEN && \\\n",
    "    python -m lerobot.datasets.v30.convert_dataset_v21_to_v30 --repo-id=$repo_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be92127a",
   "metadata": {},
   "source": [
    "### データセットのロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839c2fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lerobot.datasets.lerobot_dataset import LeRobotDataset\n",
    "\n",
    "repo_id = \"EngineerCafeJP/record-test-2025-10-07-21-26-29\"\n",
    "\n",
    "# TODO: torchcodecだとVideoDecoderの読み込みに失敗する\n",
    "dataset = LeRobotDataset(repo_id, video_backend=\"pyav\")\n",
    "\n",
    "sample = dataset[100]\n",
    "sample.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecaaf131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# デルタタイムスタンプを使って時系列ウィンドウを取得\n",
    "\n",
    "# 現在のフレームから-0.2秒、-0.1秒、0.0秒の3フレームを取得\n",
    "# TODO: v3.0移行でキー名が壊れている\n",
    "delta_timestamps = {\n",
    "    \"observation.images.images.top\": [-0.2, -0.1, 0.0]\n",
    "}\n",
    "\n",
    "dataset = LeRobotDataset(repo_id, delta_timestamps=delta_timestamps, video_backend=\"pyav\")\n",
    "\n",
    "# Accessing an index now returns a stack for the specified key(s)\n",
    "sample = dataset[100]\n",
    "sample[\"observation.images.images.top\"].shape  # torch.Size([3, 3, H, W])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d665980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練時はDataLoaderでラップする\n",
    "\n",
    "batch_size = 16\n",
    "data_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "for batch in data_loader:\n",
    "    observations = batch[\"observation.state\"].to(device)\n",
    "    actions = batch[\"action\"].to(device)\n",
    "    images = batch[\"observation.images.images.top\"].to(device)\n",
    "    # model.forward(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279a0551",
   "metadata": {},
   "source": [
    "### ストリーミング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649eba44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lerobot.datasets.streaming_dataset import StreamingLeRobotDataset\n",
    "\n",
    "repo_id = \"EngineerCafeJP/record-test-2025-10-07-21-26-29\"\n",
    "# torchcodecしか対応していない\n",
    "dataset = StreamingLeRobotDataset(repo_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698f3e07",
   "metadata": {},
   "source": [
    "### ディレクトリレイアウト"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf52555a",
   "metadata": {},
   "source": [
    "[EngineerCafeJP/record-test-2025-10-07-21-26-29][1]\n",
    "\n",
    "[1]: https://huggingface.co/datasets/EngineerCafeJP/record-test-2025-10-07-21-26-29/tree/main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209a5990",
   "metadata": {},
   "source": [
    "- meta/info.json \n",
    "    - スキーマ\n",
    "    - FPS\n",
    "    - コードベースのバージョン\n",
    "    - データ・動画シャードを見つけるためのパステンプレート\n",
    "- meta/stats.json\n",
    "    - 正規化に使用するグローバルな特徴量の統計\n",
    "- meta/tasks.jsonl\n",
    "    - 整数IDとタスクのマッピング\n",
    "- meta/episodes/\n",
    "    - エピソードごとの記録（長さ、タスク、オフセット）\n",
    "    - チャンク化されたParquet形式\n",
    "- data/\n",
    "    - フレームごとのParquetシャード\n",
    "    - 各ファイルに多くのエピソードが含まれる\n",
    "- videos/\n",
    "    - カメラごとのMP4シャード\n",
    "    - 各ファイルに多くのエピソードが含まれる"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ec2c4d",
   "metadata": {},
   "source": [
    "### 訓練時の画像のデータ拡張"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714df03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lerobot.datasets.lerobot_dataset import LeRobotDataset\n",
    "from lerobot.datasets.transforms import ImageTransforms, ImageTransformsConfig, ImageTransformConfig\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# オプション1：デフォルトの変換設定を使用（デフォルトでは無効）\n",
    "transforms_config = ImageTransformsConfig(\n",
    "    enable=True,  # 変換を有効化\n",
    "    max_num_transforms=3,  # 1フレームあたり最大3つの変換を適用\n",
    "    random_order=False,  # 標準の順序で適用\n",
    ")\n",
    "transforms = ImageTransforms(transforms_config)\n",
    "\n",
    "repo_id = \"EngineerCafeJP/record-test-2025-10-07-21-26-29\"\n",
    "\n",
    "dataset = LeRobotDataset(\n",
    "    repo_id=repo_id,\n",
    "    image_transforms=transforms,\n",
    "    video_backend=\"pyav\",\n",
    ")\n",
    "\n",
    "sample = dataset[100]\n",
    "image = sample[\"observation.images.images.top\"]\n",
    "plt.imshow(image.permute(1, 2, 0))\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209b14bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# オプション2：カスタムの変換設定を作成\n",
    "custom_transforms_config = ImageTransformsConfig(\n",
    "    enable=True,\n",
    "    max_num_transforms=2,\n",
    "    random_order=True,\n",
    "    tfs={\n",
    "        \"brightness\": ImageTransformConfig(\n",
    "            weight=1.0,\n",
    "            type=\"ColorJitter\",\n",
    "            kwargs={\"brightness\": (0.7, 1.3)}  # 明るさの範囲を調整\n",
    "        ),\n",
    "        \"contrast\": ImageTransformConfig(\n",
    "            weight=2.0,  # 重みが大きいほど選択されやすい\n",
    "            type=\"ColorJitter\",\n",
    "            kwargs={\"contrast\": (0.8, 1.2)}\n",
    "        ),\n",
    "        \"sharpness\": ImageTransformConfig(\n",
    "            weight=0.5,  # 重みが小さいほど選択されにくい\n",
    "            type=\"SharpnessJitter\",\n",
    "            kwargs={\"sharpness\": (0.3, 2.0)}\n",
    "        ),\n",
    "    }\n",
    ")\n",
    "\n",
    "repo_id = \"EngineerCafeJP/record-test-2025-10-07-21-26-29\"\n",
    "\n",
    "dataset = LeRobotDataset(\n",
    "    repo_id=repo_id,\n",
    "    image_transforms=ImageTransforms(custom_transforms_config),\n",
    "    video_backend=\"pyav\",\n",
    ")\n",
    "\n",
    "sample = dataset[100]\n",
    "image = sample[\"observation.images.images.top\"]\n",
    "plt.imshow(image.permute(1, 2, 0))\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58fb61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# オプション3：純粋なtorchvisionの変換を使用\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "torchvision_transforms = v2.Compose([\n",
    "    v2.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    v2.GaussianBlur(kernel_size=3, sigma=(0.1, 2.0)),\n",
    "])\n",
    "\n",
    "repo_id = \"EngineerCafeJP/record-test-2025-10-07-21-26-29\"\n",
    "\n",
    "dataset = LeRobotDataset(\n",
    "    repo_id=repo_id,\n",
    "    image_transforms=torchvision_transforms\n",
    ")\n",
    "\n",
    "plt.imshow(image.permute(1, 2, 0))\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a1a78e",
   "metadata": {},
   "source": [
    "### ベストプラクティス\n",
    "\n",
    "- 控えめに始める: 小さな範囲（明るさ0.9-1.1など）からはじめ徐々に増やす\n",
    "- テストする: 変換後の画像を確認する\n",
    "- トレーニングを監視する: 順調に学習できているかの経過を観察する\n",
    "- ドメインに合わせる: 照明条件が変わる場合は、明るさ・コントラストの変換を使用する\n",
    "- 賢く組み合わせる: 同時に多くの変換を適用するとトレーニングが不安定になる"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
