{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39c71e0e",
   "metadata": {},
   "source": [
    "# LeRobot v0.4.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878b6d63",
   "metadata": {},
   "source": [
    "## 概要\n",
    "\n",
    "[LeRobot v0.4.0][1]の新機能を試す\n",
    "\n",
    "[1]: https://github.com/huggingface/lerobot/releases/tag/v0.4.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f960554",
   "metadata": {},
   "source": [
    "- Dataset v3の導入\n",
    "    - 1エピソード1ファイルから、複数のエピソードを単一のParquet/MP4ファイルに集約する形式に変更\n",
    "    - エピソードの参照にリレーショナルメタデータを使用\n",
    "    - StreamingLeRobotDatasetによりデータセットのストリームでのダウンロードが可能になった\n",
    "    - v2.1データセットをv3に変換するスクリプトを追加 \n",
    "- 新しいポリシーの追加\n",
    "    - NVIDIA GR00TN 1.5を追加\n",
    "    - LiberoとMetaWorldのシミュレーション環境を追加\n",
    "    - Reachy 2ロボットとIntel XPUバックエンドへの対応を追加\n",
    "- パフォーマンスの向上\n",
    "    - accelerateライブラリを用いたマルチGPUトレーニングに対応\n",
    "    - データ拡張機能にアフィン変換を追加\n",
    "    - APIの拡張（build_inference_frame・make_robot_action）\n",
    "- コードベースの大幅なリファクタリング\n",
    "    - RL・非同期処理関連の実装がトップレベルに移動\n",
    "    - mypyによる型チェックを導入\n",
    "    - 古いコンポーネントを非推奨化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd6804d",
   "metadata": {},
   "source": [
    "## 検証設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10b493a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104dec33",
   "metadata": {},
   "source": [
    "## インストール"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5b82af",
   "metadata": {},
   "source": [
    "[Install LeRobot][1]\n",
    "\n",
    "[1]: https://huggingface.co/docs/lerobot/en/installation#install-lerobot-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc033614",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python --version # 3.10\n",
    "!ffmpeg -version # 7.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2824f527",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists(\"lerobot\"):\n",
    "    !git clone --branch v0.4.0-1-gc75455a6 --depth 1 https://github.com/huggingface/lerobot.git\n",
    "\n",
    "%cd lerobot\n",
    "%pip install -qe . # LeRobotの依存関係をインストール\n",
    "%pip show lerobot # 0.4.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6577d074",
   "metadata": {},
   "source": [
    "## Dataset v3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1789dac1",
   "metadata": {},
   "source": [
    "### エピソードベースからファイルベースへ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daeef370",
   "metadata": {},
   "source": [
    "Dataset v2.1は、ファイルシステムの制限により数百万ものエピソードに対応できなかった\n",
    "\n",
    "Dataset v3では、複数のエピソードをまとめたファイルベースに変更され、より大きなファイルで管理するようになった:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90da19cf",
   "metadata": {},
   "source": [
    "![](image/dataset.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7fbec10",
   "metadata": {},
   "source": [
    "### データセットの構成\n",
    "\n",
    "- テーブルデータ\n",
    "    - 状態・アクション・タイムスタンプ\n",
    "    - Apache Parquet形式\n",
    "- 視覚データ\n",
    "    - カメラフレームは連結されMP4にエンコード\n",
    "    - 同一エピソードでグループ化\n",
    "    - シャーディングはカメラごとに行う\n",
    "- メタデータ\n",
    "    - フレームレート・統計量・共有Parquet/MP4ファイルへのエピソードの開始終了オフセット \n",
    "    - JSON・Parquet形式"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be92127a",
   "metadata": {},
   "source": [
    "### データセットのロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564f16bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U huggingface-hub==0.35.3 traitlets==5.14.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1444b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip show tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea78e393",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "snapshot_download(repo_id=\"defunct-datasets/amazon_reviews_multi\", repo_type=\"dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3c5cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e59445c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from lerobot.datasets.lerobot_dataset import LeRobotDataset, CODEBASE_VERSION\n",
    "\n",
    "repo_id = \"yaak-ai/L2D-v3\"\n",
    "\n",
    "# 1) Load from the Hub (cached locally)\n",
    "dataset = LeRobotDataset(repo_id, force_cache_sync=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c918844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Random access by index\n",
    "sample = dataset[100]\n",
    "print(sample)\n",
    "# {\n",
    "#   'observation.state': tensor([...]),\n",
    "#   'action': tensor([...]),\n",
    "#   'observation.images.front_left': tensor([C, H, W]),\n",
    "#   'timestamp': tensor(1.234),\n",
    "#   ...\n",
    "# }\n",
    "\n",
    "# 3) Temporal windows via delta_timestamps (seconds relative to t)\n",
    "delta_timestamps = {\n",
    "    \"observation.images.front_left\": [-0.2, -0.1, 0.0]  # 0.2s and 0.1s before current frame\n",
    "}\n",
    "\n",
    "dataset = LeRobotDataset(repo_id, delta_timestamps=delta_timestamps)\n",
    "\n",
    "# Accessing an index now returns a stack for the specified key(s)\n",
    "sample = dataset[100]\n",
    "print(sample[\"observation.images.front_left\"].shape)  # [T, C, H, W], where T=3\n",
    "\n",
    "# 4) Wrap with a DataLoader for training\n",
    "batch_size = 16\n",
    "data_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "for batch in data_loader:\n",
    "    observations = batch[\"observation.state\"].to(device)\n",
    "    actions = batch[\"action\"].to(device)\n",
    "    images = batch[\"observation.images.front_left\"].to(device)\n",
    "    # model.forward(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebab13f8",
   "metadata": {},
   "source": [
    "### ディレクトリレイアウト\n",
    "\n",
    "- "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
